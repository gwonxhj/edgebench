# EdgeBench

> Edge AI Inference Profiling Framework  
> ONNX ëª¨ë¸ì˜ êµ¬ì¡° ë¶„ì„ê³¼ ì‹¤ì œ ì¶”ë¡  ì„±ëŠ¥ì„ ì •ëŸ‰í™”í•˜ëŠ” ê°œë°œììš© ë²¤ì¹˜ë§ˆí¬ ë„êµ¬

---

## ğŸ“Œ í”„ë¡œì íŠ¸ ê°œìš”

EdgeBenchëŠ” ì—£ì§€ í™˜ê²½ì—ì„œ AI ëª¨ë¸ì„ ë°°í¬í•˜ê¸° ì „ì—  
ëª¨ë¸ì˜ êµ¬ì¡°ì  íŠ¹ì„±ê³¼ ì‹¤ì œ ì¶”ë¡  ì„±ëŠ¥ì„ ë¶„ì„í•˜ê¸° ìœ„í•œ CLI ê¸°ë°˜ ë„êµ¬ì…ë‹ˆë‹¤.

ì •í™•ë„(Accuracy)ë§Œìœ¼ë¡œëŠ” ëª¨ë¸ì˜ ë°°í¬ ê°€ëŠ¥ì„±ì„ íŒë‹¨í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

EdgeBenchëŠ” ë‹¤ìŒì„ ì œê³µí•©ë‹ˆë‹¤:

- ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
- ëª¨ë¸ íŒŒì¼ í¬ê¸° í™•ì¸
- FLOPs ì¶”ì •
- CPU ê¸°ë°˜ ì‹¤ì œ ì¶”ë¡  latency ì¸¡ì •
- JSON í˜•íƒœì˜ ì •ëŸ‰ ë¦¬í¬íŠ¸ ì¶œë ¥

---

## ğŸ¯ ì™œ í•„ìš”í•œê°€?

Jetson, RK3588, CPU-only í™˜ê²½ê³¼ ê°™ì€ ì—£ì§€ ë””ë°”ì´ìŠ¤ì—ì„œëŠ”  
ëª¨ë¸ì˜ ì •í™•ë„ë³´ë‹¤ ë‹¤ìŒ ìš”ì†Œê°€ ë” ì¤‘ìš”í•©ë‹ˆë‹¤:

- ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥ ì—¬ë¶€
- ì—°ì‚°ëŸ‰
- ë©”ëª¨ë¦¬ ìš”êµ¬ëŸ‰
- ì‹¤ì œ ì¶”ë¡  ì§€ì—° ì‹œê°„

EdgeBenchëŠ” ì´ëŸ¬í•œ ì •ë³´ë¥¼ í•˜ë‚˜ì˜ CLI ì¸í„°í˜ì´ìŠ¤ì—ì„œ í†µí•© ì œê³µí•©ë‹ˆë‹¤.

---

## ğŸ§  ì•„í‚¤í…ì²˜

CLI ê¸°ë°˜ êµ¬ì¡°:

- Analyzer: ì •ì  ëª¨ë¸ ë¶„ì„
- Profiler: ë™ì  ì¶”ë¡  ì„±ëŠ¥ ì¸¡ì •
- Engine Interface: ì¶”ë¡  ì—”ì§„ ì¶”ìƒí™” ê³„ì¸µ

í˜„ì¬ ì§€ì›:
- ONNX Runtime CPU

í–¥í›„ í™•ì¥ ì˜ˆì •:
- TensorRT
- RKNN
- Jetson CUDA Backend
- C++ ì¶”ë¡  ì—”ì§„

---

## ğŸ›  ì˜ˆì • ê¸°ëŠ¥ (MVP)

- ONNX ëª¨ë¸ ë¡œë“œ
- íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
- FLOPs ì¶”ì •
- CPU latency ë²¤ì¹˜ë§ˆí¬
- JSON ë¦¬í¬íŠ¸ ì¶œë ¥

---

## ğŸ—º ê°œë°œ ë¡œë“œë§µ

ìì„¸í•œ ê³„íšì€ Roadmap.md ì°¸ê³ 

---

## ğŸ“ˆ Benchmarks

EdgeBenchëŠ” ì •ì  ì§€í‘œ(FLOPs, Parameters)ì™€ ë™ì  ì§€í‘œ(Latency)ë¥¼ í•˜ë‚˜ì˜ ë¦¬í¬íŠ¸ ìŠ¤í‚¤ë§ˆë¡œ í†µí•© ì œê³µí•©ë‹ˆë‹¤.

> í™˜ê²½: GitHub Codespaces (Linux x86_64), ONNX Runtime CPU  
> ì„¤ì •: warmup=10, intra_threads=1, inter_threads=1

### YOLOv8n (640Ã—640, batch=1)

> í™˜ê²½: GitHub Codespaces (Linux x86_64), ONNX Runtime CPU  
> ì„¤ì •: warmup=10, runs=50, intra_threads=1, inter_threads=1

- Parameters: 3,193,923
- FLOPs (est): 644,336,844,800
- Latency (ms):
  - mean: 120.22
  - p50: 115.67
  - p90: 125.57
  - p99: 166.38
  - std: 11.84
  - min/max: 113.42 / 172.68

ë¦¬í¬íŠ¸ JSON: `reports/yolov8n__onnxruntime_cpu__b1__r50__*.json`

### ToyNet (FLOPs â†” Latency Scaling Validation)

> í™˜ê²½: GitHub Codespaces (Linux x86_64), ONNX Runtime CPU  
> ì„¤ì •: warmup=10, runs=300, intra_threads=1, inter_threads=1  
> ëª¨ë¸: Conv/Linear ê¸°ë°˜ ToyNet (dynamic H/W)

| Input (HxW) | FLOPs (est) | Mean (ms) | P99 (ms) |
|---:|---:|---:|---:|
| 224Ã—224 | 126,444,160 | 0.546 | 1.027 |
| 320Ã—320 | 258,048,640 | 1.073 | 1.470 |
| 640Ã—640 | 1,032,192,640 | 4.424 | 6.771 |

> ì…ë ¥ í•´ìƒë„ ì¦ê°€ì— ë”°ë¼ FLOPsëŠ” ë©´ì (HÃ—W)ì— ë¹„ë¡€í•´ ì¦ê°€í•˜ë©°,  
> ì‹¤ì œ latency ì—­ì‹œ ìœ ì‚¬í•œ ìŠ¤ì¼€ì¼ë§ ê²½í–¥ì„ ë³´ì„ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì‹¤í–‰ ëª…ë ¹

```bash
edgebench profile models/yolov8n.onnx \
  --warmup 10 --runs 50 --batch 1 \
  --intra-threads 1 --inter-threads 1
```

ë¦¬í¬íŠ¸ JSON: `reports/yolov8n__onnxruntime_cpu__b1__r50__*.json`

ë²¤ì¹˜ë§ˆí¬ ì¸¡ì • ë°©ë²•ë¡ : `docs/benchmarking.md`

## ğŸ“œ License

MIT License

---


